{
  "updatedAt": "2026-02-05T16:18:39.059Z",
  "createdAt": "2025-11-22T11:05:19.565Z",
  "id": "erVTZf6CW7PbLwfJ",
  "name": "Case Study Generator",
  "description": "",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "updates": [
          "message"
        ],
        "additionalFields": {}
      },
      "id": "d9cc2d87-0308-4588-b2b1-5c2382dbd63f",
      "name": "Telegram Trigger",
      "type": "n8n-nodes-base.telegramTrigger",
      "typeVersion": 1.1,
      "position": [
        -848,
        1040
      ],
      "webhookId": "ddvb-telegram-bot",
      "credentials": {
        "telegramApi": {
          "id": "BnEQsFHcvbF7jdMc",
          "name": "DDVB PR Case Study Bot"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse Telegram input (expecting Russian)\nconst message = $input.item.json.message || {};\nconst userMessage = message.text || '';\nconst chatId = message.chat.id;\nconst userId = message.from.id;\nconst userName = message.from.first_name || 'User';\n\n// Validate Russian input\nconst hasCyrillic = /[–ê-–Ø–∞-—è–Å—ë]/.test(userMessage);\nif (!hasCyrillic) {\n  throw new Error('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. / Please send your request in Russian.');\n}\n\n// Extract Topic (heuristic)\nlet topic = '–≤–∞—à–∏–º –∑–∞–ø—Ä–æ—Å–æ–º';\n// Look for text after common prepositions: –æ, –ø—Ä–æ, –¥–ª—è, –Ω–∞—Å—á–µ—Ç\nconst topicMatch = userMessage.match(/(?:–æ|–ø—Ä–æ|–¥–ª—è|–Ω–∞—Å—á–µ—Ç|–∫–µ–π—Å|—Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å)\\s+([–∞-—è—ëa-z0-9\\s\"¬´¬ª-]+?)(?:$|\\.|,|\\n)/i);\nif (topicMatch && topicMatch[1]) {\n    topic = topicMatch[1].trim();\n    if (topic.length > 50) topic = topic.substring(0, 47) + '...';\n}\n\n// Parse key information from message (Russian patterns)\nconst messageData = {\n  originalMessage: userMessage,\n  chatId: chatId,\n  userId: userId,\n  userName: userName,\n  topic: topic,\n  timestamp: new Date().toISOString(),\n  \n  // Extract potential entities (Russian + English publication names)\n  hasPublication: /sostav|—Å–æ—Å—Ç–∞–≤|forbes|—Ñ–æ—Ä–±—Å|rbc|—Ä–±–∫|vc\\.ru|–≤—Å\\.—Ä—É|cossa|–∫–æ—Å—Å–∞|adindex|–∞–¥–∏–Ω–¥–µ–∫—Å/i.test(userMessage),\n  hasMetrics: /\\d+%|\\$\\d+|‚ÇΩ\\d+|–º–∏–ª–ª–∏–æ–Ω|–º–ª–Ω|–≤—ã—Ä–æ—Å–ª–∏|—Ä–æ—Å—Ç|–ø—Ä–æ—Ü–µ–Ω—Ç|–ø—Ä–∏–≤–ª–µ–∫|—É–≤–µ–ª–∏—á–∏–ª/i.test(userMessage),\n  hasClientName: true, // Will be refined in OpenAI\n  \n  // Determine if this is initial request or follow-up\n  isInitialRequest: !userMessage.toLowerCase().includes('–¥–∞') && \n                     !userMessage.toLowerCase().includes('–Ω–µ—Ç'),\n  \n  // Prepare for next nodes\n  needsResearch: userMessage.length < 200, // Short messages may need more context\n  readyForGeneration: userMessage.length > 200 && /–∫–ª–∏–µ–Ω—Ç|–ø—Ä–æ–µ–∫—Ç|—Ä–µ–±—Ä–µ–Ω–¥–∏–Ω–≥|–±—Ä–µ–Ω–¥–∏–Ω–≥|–∫–æ–º–ø–∞–Ω–∏—è|—É–ø–∞–∫–æ–≤–∫–∞/i.test(userMessage)\n};\n\nreturn { json: messageData };"
      },
      "id": "8e46d1ac-84bf-4071-9c5b-32f09c71bbe1",
      "name": "Parse Telegram Input",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -624,
        1040
      ]
    },
    {
      "parameters": {
        "jsCode": "const baseData = $('Parse Telegram Input').item.json;\n\nconst getPrompt = (nodeName) => {\n  try {\n    const item = $(nodeName).item;\n    \n    // DEBUG LOGGING\n    console.log(`--- Fetching prompt from ${nodeName} ---`);\n    if (item.json) {\n      console.log(`JSON keys: ${Object.keys(item.json).join(', ')}`);\n      if (item.json.encoding) console.log(`Encoding: ${item.json.encoding}`);\n    }\n\n    // 1. Check for Binary data\n    if (item.binary) {\n      const binaryKey = Object.keys(item.binary)[0];\n      if (binaryKey && item.binary[binaryKey]) {\n        const binaryData = item.binary[binaryKey];\n        if (binaryData.data) {\n          if (binaryData.data.startsWith('filesystem')) {\n             return `[ERROR: Binary data is filesystem pointer, not content]`; \n          }\n          return Buffer.from(binaryData.data, 'base64').toString('utf8');\n        }\n      }\n    }\n\n    // 2. Check for Text content (Handle Base64 from Github nodes)\n    const json = item.json;\n    \n    if (json.content && typeof json.content === 'string') {\n       // Check for Base64 encoding (standard Github API response)\n       if (json.encoding === 'base64') {\n         return Buffer.from(json.content, 'base64').toString('utf8');\n       }\n       return json.content;\n    }\n    \n    if (json.data && typeof json.data === 'string') return json.data;\n    if (json.text && typeof json.text === 'string') return json.text;\n    if (json.body && typeof json.body === 'string') return json.body;\n\n    return `[ERROR: No prompt found in ${nodeName}]`;\n  } catch (error) {\n    console.log(`Error in getPrompt: ${error.message}`);\n    return `[ERROR: Could not fetch prompt from ${nodeName}: ${error.message}]`;\n  }\n};\n\nconst prompts = {\n  perplexityResearch: getPrompt('Fetch Perplexity Prompt'),\n  openaiGeneration: getPrompt('Fetch Generation Prompt'), \n  russianHumanization: getPrompt('Fetch Humanization Prompt')\n};\n\nconsole.log('--- Final Prompts ---');\nconsole.log('Perplexity Length:', prompts.perplexityResearch.length);\nconsole.log('Generation Length:', prompts.openaiGeneration.length);\nconsole.log('Humanization Length:', prompts.russianHumanization.length);\nconsole.log('Generation Preview:', prompts.openaiGeneration.substring(0, 100));\n\nreturn {\n  json: {\n    ...baseData,\n    prompts,\n    promptsLoaded: true,\n    promptVersion: 'main',\n    promptLoadTimestamp: new Date().toISOString()\n  }\n};"
      },
      "id": "2b79636f-4b06-47e4-a9d5-bdfefd020bf8",
      "name": "Assemble Prompts",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        352,
        1040
      ]
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "conditions": [
                  {
                    "leftValue": "={{ $json.needsResearch }}",
                    "operator": {
                      "operation": "equals",
                      "type": "boolean"
                    },
                    "rightValue": true
                  }
                ],
                "options": {
                  "caseSensitive": false,
                  "looseTypeValidation": true
                }
              },
              "renameOutput": true,
              "outputKey": "needsResearch"
            },
            {
              "conditions": {
                "conditions": [
                  {
                    "leftValue": "={{ $json.readyForGeneration }}",
                    "operator": {
                      "operation": "equals",
                      "type": "boolean"
                    },
                    "rightValue": true
                  }
                ],
                "options": {
                  "caseSensitive": false,
                  "looseTypeValidation": true
                }
              },
              "renameOutput": true,
              "outputKey": "readyForGeneration"
            }
          ]
        },
        "options": {
          "fallbackOutput": "extra"
        }
      },
      "id": "bb1af2bd-2753-48f9-ba17-721dbf65e6ea",
      "name": "Route Decision",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3,
      "position": [
        576,
        1040
      ]
    },
    {
      "parameters": {
        "jsCode": "// Combine research with original message\n// Handle both native Perplexity node and HTTP Request node output formats\nconst originalData = $('Parse Telegram Input').item.json;\nconst inputData = $input.item.json;\n\n// Native Perplexity node outputs content directly, HTTP Request outputs choices array\nlet researchResponse;\nif (inputData.content) {\n  // Native Perplexity node format\n  researchResponse = inputData.content;\n} else if (inputData.text) {\n  // Alternative format\n  researchResponse = inputData.text;\n} else if (inputData.choices && inputData.choices[0] && inputData.choices[0].message) {\n  // HTTP Request format\n  researchResponse = inputData.choices[0].message.content;\n} else if (inputData.message && inputData.message.content) {\n  // Another possible format\n  researchResponse = inputData.message.content;\n} else {\n  // Fallback - try to stringify\n  researchResponse = JSON.stringify(inputData);\n}\n\nreturn {\n  json: {\n    ...originalData,\n    researchContext: researchResponse,\n    enrichedMessage: originalData.originalMessage + \"\\n\\n[Research Context: \" + researchResponse + \"]\",\n    readyForGeneration: true\n  }\n};"
      },
      "id": "8cabd421-2e1e-4044-b22f-80e0221bba55",
      "name": "Merge Research Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1008,
        848
      ]
    },
    {
      "parameters": {
        "jsCode": "// Prepare OpenAI messages for RUSSIAN case study generation\nconst userData = $input.item.json;\nconst userMessage = userData.enrichedMessage || userData.originalMessage;\nconst systemPrompt = $('Assemble Prompts').item.json.prompts.openaiGeneration;\n\nconst messages = [\n  {\n    role: 'system',\n    content: systemPrompt\n  },\n  {\n    role: 'user',\n    content: userMessage\n  }\n];\n\nreturn {\n  json: {\n    ...userData,\n    openaiMessages: messages\n  }\n};"
      },
      "id": "36ed469e-e83b-4a2d-9c51-eea227d55af7",
      "name": "Prepare OpenAI Request",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1232,
        1040
      ]
    },
    {
      "parameters": {
        "jsCode": "// Extract Russian case study from OpenAI response\n// Handle both native Langchain OpenAI node and HTTP Request node output formats\nconst inputData = $input.item.json;\n\n// Debug: Log the input structure\nconsole.log('Input data keys:', Object.keys(inputData));\n\n// Native Langchain OpenAI node outputs to output[0].content[0].text\nlet russianCaseStudy;\n\n// Check for native Langchain OpenAI node format (most likely)\nif (inputData.output && Array.isArray(inputData.output) && inputData.output[0]) {\n  const outputItem = inputData.output[0];\n  if (outputItem.content && Array.isArray(outputItem.content) && outputItem.content[0]) {\n    const contentItem = outputItem.content[0];\n    if (contentItem.text) {\n      russianCaseStudy = contentItem.text;\n    }\n  }\n}\n\n// Fallback: check for simpler output formats\nif (!russianCaseStudy) {\n  if (typeof inputData.output === 'string') {\n    russianCaseStudy = inputData.output;\n  } else if (inputData.text) {\n    russianCaseStudy = inputData.text;\n  } else if (inputData.content) {\n    russianCaseStudy = inputData.content;\n  } else if (inputData.choices && inputData.choices[0] && inputData.choices[0].message) {\n    russianCaseStudy = inputData.choices[0].message.content;\n  } else if (inputData.message && inputData.message.content) {\n    russianCaseStudy = inputData.message.content;\n  }\n}\n\nif (!russianCaseStudy) {\n  throw new Error('Unable to extract case study from OpenAI response. Keys: ' + JSON.stringify(Object.keys(inputData)) + ', Full input: ' + JSON.stringify(inputData).substring(0, 500));\n}\n\nconst originalData = $('Prepare OpenAI Request').item.json;\n\nreturn {\n  json: {\n    ...originalData,\n    russianCaseStudy: russianCaseStudy\n  }\n};"
      },
      "id": "29a054f0-aebf-4a79-98c1-040abb4775c5",
      "name": "Extract Russian Case Study",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1680,
        1040
      ]
    },
    {
      "parameters": {
        "jsCode": "// Extract humanized Russian case study from OpenAI response\n// Handle both native Langchain OpenAI node and HTTP Request node output formats\nconst inputData = $input.item.json;\n\n// Debug: Log the input structure\nconsole.log('Input data keys:', Object.keys(inputData));\n\n// Native Langchain OpenAI node outputs to output[0].content[0].text\nlet humanizedCaseStudy;\n\n// Check for native Langchain OpenAI node format (most likely)\nif (inputData.output && Array.isArray(inputData.output) && inputData.output[0]) {\n  const outputItem = inputData.output[0];\n  if (outputItem.content && Array.isArray(outputItem.content) && outputItem.content[0]) {\n    const contentItem = outputItem.content[0];\n    if (contentItem.text) {\n      humanizedCaseStudy = contentItem.text;\n    }\n  }\n}\n\n// Fallback: check for simpler output formats\nif (!humanizedCaseStudy) {\n  if (typeof inputData.output === 'string') {\n    humanizedCaseStudy = inputData.output;\n  } else if (inputData.text) {\n    humanizedCaseStudy = inputData.text;\n  } else if (inputData.content) {\n    humanizedCaseStudy = inputData.content;\n  } else if (inputData.choices && inputData.choices[0] && inputData.choices[0].message) {\n    humanizedCaseStudy = inputData.choices[0].message.content;\n  } else if (inputData.message && inputData.message.content) {\n    humanizedCaseStudy = inputData.message.content;\n  }\n}\n\nif (!humanizedCaseStudy) {\n  throw new Error('Unable to extract humanized text from OpenAI response. Keys: ' + JSON.stringify(Object.keys(inputData)) + ', Full input: ' + JSON.stringify(inputData).substring(0, 500));\n}\n\nconst originalData = $('Extract Russian Case Study').item.json;\n\nreturn {\n  json: {\n    ...originalData,\n    russianCaseStudy: humanizedCaseStudy,\n    humanized: true\n  }\n};"
      },
      "id": "cf921bae-244b-4261-a240-14e1c3702d8c",
      "name": "Extract Humanized Text",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2336,
        1040
      ]
    },
    {
      "parameters": {
        "jsCode": "// Extract and validate Russian case study\nconst russianCaseStudy = $input.item.json.russianCaseStudy;\nconst originalData = $input.item.json;\n\n// Check for Russian quotation marks - more flexible approach\n// Check for both opening and closing marks (they can be in different parts of text)\nconst hasOpeningQuote = russianCaseStudy.includes('¬´');\nconst hasClosingQuote = russianCaseStudy.includes('¬ª');\nconst hasCompletePair = /¬´[^¬ª]*¬ª/.test(russianCaseStudy);\n// Accept if we have both marks OR at least one complete pair\nconst hasProperQuotationMarks = (hasOpeningQuote && hasClosingQuote) || hasCompletePair;\n\n// Basic validation\n// Note: Upper limit increased to 15000 since we now split long messages for Telegram\nconst validations = {\n  hasRussianText: /[–ê-–Ø–∞-—è–Å—ë]/.test(russianCaseStudy),\n  hasQuotes: (russianCaseStudy.match(/>/g) || []).length >= 2,\n  hasProperQuotationMarks: hasProperQuotationMarks,\n  hasTitle: /^[^\\n]+/.test(russianCaseStudy),\n  lengthOk: russianCaseStudy.length >= 1500 && russianCaseStudy.length <= 15000,\n  hasDDVBBranding: /DDVB|–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ|–∫–æ–º–∞–Ω–¥–∞/.test(russianCaseStudy)\n};\n\nconst allValid = Object.values(validations).every(v => v === true);\n\n// Calculate word count for better feedback\nconst wordCount = russianCaseStudy.split(/\\s+/).length;\n\n// Provide more detailed feedback on what failed\nconst failedChecks = Object.entries(validations)\n  .filter(([key, value]) => !value)\n  .map(([key]) => key);\n\nconst validationSummary = allValid \n  ? `‚úÖ All quality checks passed (humanized)\\nüìä Length: ${russianCaseStudy.length} chars, ${wordCount} words`\n  : `‚ö†Ô∏è Some quality checks failed: ${failedChecks.join(', ')}\\nüìä Length: ${russianCaseStudy.length} chars, ${wordCount} words`;\n\nreturn {\n  json: {\n    ...originalData,\n    russianCaseStudy: russianCaseStudy,\n    validations: validations,\n    isValid: allValid,\n    wordCount: wordCount,\n    characterCount: russianCaseStudy.length,\n    validationSummary: validationSummary\n  }\n};"
      },
      "id": "f4880e69-b664-43b6-a5f9-5ad48642f873",
      "name": "Validate Russian Case Study",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2560,
        1040
      ]
    },
    {
      "parameters": {
        "jsCode": "// Split long messages into chunks for Telegram (4096 char limit)\nconst data = $input.item.json;\nconst russianCaseStudy = data.russianCaseStudy || '';\nconst validationSummary = data.validationSummary || '';\n\n// Telegram limit is 4096 characters.\n// Using HTML mode (safe for URLs/underscores) allows us to use the full limit.\nconst MAX_CHUNK_SIZE = 4096;\n// Use HTML bold tag instead of Markdown\nconst header = 'üìÑ <b>–ö–µ–π—Å DDVB –≥–æ—Ç–æ–≤!</b>\\n\\n';\nconst footer = '\\n\\n---\\n\\n' + validationSummary;\n\n// Build full message\nconst fullMessage = header + russianCaseStudy + footer;\n\n// If message fits in one chunk, return single item\nif (fullMessage.length <= MAX_CHUNK_SIZE) {\n  return {\n    json: {\n      ...data,\n      messageChunk: fullMessage,\n      totalChunks: 1,\n      currentChunk: 1\n    }\n  };\n}\n\n// Split into chunks - try to preserve paragraph boundaries\nconst chunks = [];\nconst paragraphs = russianCaseStudy.split('\\n\\n');\nlet currentChunk = '';\nlet chunkNumber = 1;\n\nfor (let i = 0; i < paragraphs.length; i++) {\n  const paragraph = paragraphs[i];\n  const testChunk = currentChunk + (currentChunk ? '\\n\\n' : '') + paragraph;\n  \n  // If adding this paragraph would exceed limit\n  if (testChunk.length > MAX_CHUNK_SIZE && currentChunk.length > 0) {\n    // Save current chunk with header\n    const chunkHeader = chunkNumber === 1 ? header : `üìÑ <b>–ö–µ–π—Å DDVB –≥–æ—Ç–æ–≤!</b> (—á–∞—Å—Ç—å ${chunkNumber})\\n\\n`;\n    chunks.push(chunkHeader + currentChunk);\n    chunkNumber++;\n    currentChunk = paragraph;\n  } else {\n    currentChunk = testChunk;\n  }\n  \n  // If single paragraph is too long, split by sentences\n  if (currentChunk.length > MAX_CHUNK_SIZE) {\n    const sentences = paragraph.split(/(?<=[.!?])\\s+/);\n    currentChunk = currentChunk.replace(paragraph, '').trim();\n    \n    for (const sentence of sentences) {\n      const testSentence = currentChunk + (currentChunk ? ' ' : '') + sentence;\n      if (testSentence.length > MAX_CHUNK_SIZE && currentChunk.length > 0) {\n        const chunkHeader = chunkNumber === 1 ? header : `üìÑ <b>–ö–µ–π—Å DDVB –≥–æ—Ç–æ–≤!</b> (—á–∞—Å—Ç—å ${chunkNumber})\\n\\n`;\n        chunks.push(chunkHeader + currentChunk);\n        chunkNumber++;\n        currentChunk = sentence;\n      } else {\n        currentChunk = testSentence;\n      }\n    }\n  }\n}\n\n// Add remaining chunk\nif (currentChunk.trim().length > 0) {\n  const chunkHeader = chunkNumber === 1 ? header : `üìÑ <b>–ö–µ–π—Å DDVB –≥–æ—Ç–æ–≤!</b> (—á–∞—Å—Ç—å ${chunkNumber})\\n\\n`;\n  chunks.push(chunkHeader + currentChunk.trim());\n}\n\n// Add footer to last chunk if it fits\nif (chunks.length > 0) {\n  const lastChunk = chunks[chunks.length - 1];\n  if (lastChunk.length + footer.length <= MAX_CHUNK_SIZE) {\n    chunks[chunks.length - 1] = lastChunk + footer;\n  } else {\n    // Footer as separate message if it doesn't fit\n    chunks.push(footer);\n  }\n}\n\n// Return multiple items, one per chunk (n8n will process each)\nreturn chunks.map((chunk, index) => ({\n  json: {\n    ...data,\n    messageChunk: chunk,\n    totalChunks: chunks.length,\n    currentChunk: index + 1\n  }\n}));"
      },
      "id": "8246f0bc-caaf-43f7-8283-f9de672a2ca5",
      "name": "Split Message for Telegram",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2784,
        1040
      ]
    },
    {
      "parameters": {
        "chatId": "={{ $json.chatId }}",
        "text": "={{ $json.messageChunk }}",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "id": "64c1fcbd-5d9f-488f-a53c-11873524ef7b",
      "name": "Send to Telegram",
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.1,
      "position": [
        3008,
        1040
      ],
      "webhookId": "c715e2db-3abe-41f1-9f92-b1cd0b0bc7f8",
      "credentials": {
        "telegramApi": {
          "id": "BnEQsFHcvbF7jdMc",
          "name": "DDVB PR Case Study Bot"
        }
      }
    },
    {
      "parameters": {
        "content": "## 1. Set Up API Credentials\n\n**Get API Keys:**\n\n1. **OpenAI API Key:**\n   - Go to [OpenAI Platform](https://platform.openai.com/api-keys)\n   - Create new API key\n   - Ensure GPT-5 model access\n   - Add funds to billing account\n\n2. **Perplexity API Key:**\n   - Go to [Perplexity Settings](https://www.perplexity.ai/settings/api)\n   - Generate API key\n   - Add to n8n credentials\n\n3. **Telegram Bot Token:**\n   - Message @BotFather on Telegram\n   - Use `/newbot` command\n   - Copy bot token\n   - Add to n8n Telegram credentials",
        "height": 340,
        "width": 380
      },
      "id": "97791bfe-a19c-4d63-9f7a-8fbf705c4b9e",
      "name": "Setup API Credentials",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -960,
        624
      ]
    },
    {
      "parameters": {
        "content": "## 2. Russian Input Format\n\n**Send Case Study Request in Russian:**\n\n‚úÖ **Required Information:**\n- Client name and industry\n- Project type (branding, rebranding, packaging, etc.)\n- Target publication (Sostav.ru, Forbes Russia, etc.)\n- Business results/metrics\n\nüìù **Example Message:**\n```\n–°–æ–∑–¥–∞–π –∫–µ–π—Å DDVB –¥–ª—è Sostav.ru –æ \n—Ä–µ–±—Ä–µ–Ω–¥–∏–Ω–≥–µ –ø–∏–≤–æ–≤–∞—Ä–Ω–∏ \"–•–º–µ–ª—å & –°–æ–ª–æ–¥\".\n–ü—Ä–æ–¥–∞–∂–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 45% –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ \n–Ω–æ–≤–æ–π –∞–π–¥–µ–Ω—Ç–∏–∫–∏ –æ—Ç DDVB.\n```\n\nüí° **Tip:** More details = better case study!",
        "height": 504,
        "width": 380
      },
      "id": "b45988f5-aa2a-4601-8ffb-4d1bc2dd059f",
      "name": "Russian Input Requirements",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -992,
        1312
      ]
    },
    {
      "parameters": {
        "content": "## 3. Research Phase\n\n**Perplexity AI Research:**\n\nüîç **What it does:**\n- Translates Russian request to English\n- Researches company background\n- Analyzes industry context\n- Identifies competitive landscape\n- Finds potential project drivers\n\nüìä **Output Format:**\n- Company background\n- Brand & market context\n- Industry insights\n- Business drivers\n\n‚è±Ô∏è **Typical duration:** 5-10 seconds",
        "height": 260,
        "width": 360
      },
      "id": "78f29aab-a1ed-4a1b-8539-c8f9503659d6",
      "name": "Research Phase",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        800,
        528
      ]
    },
    {
      "parameters": {
        "content": "## 4. Russian Generation\n\n**OpenAI GPT-5 Case Study Generation:**\n\nüìù **Process:**\n- Accepts Russian input + research context\n- Generates complete case study directly in Russian\n- Follows –°–ò–¢–£–ê–¶–ò–Ø-–ó–ê–î–ê–ß–ê-–†–ï–®–ï–ù–ò–ï structure\n- Creates client & agency quotes (500-700 chars)\n- Integrates DDVB branding naturally\n- Applies Russian media standards (quotation marks, typography)\n\nüìÑ **Output:** Complete Russian case study with:\n- Title & subtitle (‚â§90 chars, active voice)\n- Main text (–°–ò–¢–£–ê–¶–ò–Ø-–ó–ê–î–ê–ß–ê-–†–ï–®–ï–ù–ò–ï)\n- Client & agency quotes\n- Team composition\n- SEO metadata",
        "height": 320,
        "width": 380
      },
      "id": "731bd1ea-1d35-4989-8b9c-a2d1403206e1",
      "name": "Russian Generation Process",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1456,
        640
      ]
    },
    {
      "parameters": {
        "content": "## 5. AI Humanization\n\n**Remove AI Patterns:**\n\nüéØ **Purpose:**\nMake Russian text sound natural and human-written, not AI-generated\n\nüîß **Techniques:**\n- Remove robotic phrasing\n- Vary sentence structures\n- Eliminate bureaucratic language (–∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç)\n- Add natural flow and transitions\n- Use industry insider voice\n\n‚úÖ **Preserves:**\n- All facts and metrics\n- DDVB branding\n- Russian media standards\n- Client & agency quotes\n- Team composition\n\nüí° **Result:** Natural, publication-ready Russian text",
        "height": 320,
        "width": 360
      },
      "id": "71c58798-8690-41c3-b105-3928ae99e7f2",
      "name": "AI Humanization Process (Updated)",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1904,
        672
      ]
    },
    {
      "parameters": {
        "content": "## 6. Quality Validation\n\n**Automated Quality Checks:**\n\n‚úÖ **Validates:**\n- Russian text present (Cyrillic)\n- Both quotes included (client + agency)\n- Proper quotation marks ¬´–∫–∞–≤—ã—á–∫–∏¬ª\n- Title present and formatted (‚â§90 chars)\n- Length: 1,500-4,000 characters\n- DDVB branding integrated\n- –°–ò–¢–£–ê–¶–ò–Ø-–ó–ê–î–ê–ß–ê-–†–ï–®–ï–ù–ò–ï structure\n\nüìä **Validation Output:**\n- ‚úÖ All quality checks passed\n- ‚ö†Ô∏è Failed checks with details",
        "height": 280,
        "width": 340
      },
      "id": "a637de3d-0b08-437e-b8b5-57b178f752d8",
      "name": "Quality Validation Process",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2128,
        1280
      ]
    },
    {
      "parameters": {
        "content": "## 7. Telegram Delivery\n\n**Final Output Delivery:**\n\nüì≤ **What gets sent:**\n- Complete humanized Russian case study\n- Quality validation summary\n- Formatted with Markdown\n\nüéâ **Final Result:**\nPublication-ready case study for Russian media (Sostav.ru, Forbes Russia, RBC, VC.ru, etc.)\n\n‚úÖ **Ready for:**\n- Direct publication\n- Editorial review\n- Client approval",
        "height": 300,
        "width": 340
      },
      "id": "8ac380ab-1035-4449-9357-92f048a3f963",
      "name": "Telegram Delivery",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2560,
        1280
      ]
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o"
        },
        "responses": {
          "values": [
            {
              "role": "system",
              "content": "={{ $('Assemble Prompts').item.json.prompts.openaiGeneration }}"
            },
            {
              "content": "={{ $('Prepare OpenAI Request').item.json.enrichedMessage || $('Prepare OpenAI Request').item.json.originalMessage }}"
            }
          ]
        },
        "builtInTools": {},
        "options": {
          "maxTokens": 4000,
          "temperature": 0.8
        }
      },
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 2.1,
      "position": [
        1392,
        1040
      ],
      "id": "e2389aa2-f1eb-464c-b9f2-3656acd7402a",
      "name": "Generate Russian Case Study1",
      "credentials": {
        "openAiApi": {
          "id": "vMHSP02jcq5bmgAi",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o"
        },
        "responses": {
          "values": [
            {
              "role": "system",
              "content": "={{ $('Assemble Prompts').item.json.prompts.russianHumanization }}"
            },
            {
              "content": "={{ $('Extract Russian Case Study').item.json.russianCaseStudy }}"
            }
          ]
        },
        "builtInTools": {},
        "options": {
          "maxTokens": 4000,
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 2.1,
      "position": [
        1968,
        1040
      ],
      "id": "e4ef1b5e-eaa1-40ef-900f-004d2f02b1af",
      "name": "Humanize Russian Text1",
      "credentials": {
        "openAiApi": {
          "id": "vMHSP02jcq5bmgAi",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "resource": "file",
        "operation": "get",
        "owner": {
          "__rl": true,
          "value": "cybernexcorps",
          "mode": "list",
          "cachedResultName": "cybernexcorps",
          "cachedResultUrl": "https://github.com/cybernexcorps"
        },
        "repository": {
          "__rl": true,
          "value": "case-study-generator",
          "mode": "list",
          "cachedResultName": "case-study-generator",
          "cachedResultUrl": "https://github.com/cybernexcorps/case-study-generator"
        },
        "filePath": "prompts/openai-generation.md",
        "asBinaryProperty": false,
        "additionalParameters": {}
      },
      "type": "n8n-nodes-base.github",
      "typeVersion": 1.1,
      "position": [
        -48,
        1040
      ],
      "id": "340f0098-fde6-4722-97f1-efbac9d78564",
      "name": "Fetch Generation Prompt",
      "webhookId": "171c50fb-5a13-4b87-bdf6-6b800326e8f5",
      "credentials": {
        "githubApi": {
          "id": "pGlylAmPTa6t4Io0",
          "name": "GitHub account"
        }
      }
    },
    {
      "parameters": {
        "resource": "file",
        "operation": "get",
        "owner": {
          "__rl": true,
          "value": "cybernexcorps",
          "mode": "list",
          "cachedResultName": "cybernexcorps",
          "cachedResultUrl": "https://github.com/cybernexcorps"
        },
        "repository": {
          "__rl": true,
          "value": "case-study-generator",
          "mode": "list",
          "cachedResultName": "case-study-generator",
          "cachedResultUrl": "https://github.com/cybernexcorps/case-study-generator"
        },
        "filePath": "prompts/russian-humanization.md",
        "asBinaryProperty": false,
        "additionalParameters": {}
      },
      "type": "n8n-nodes-base.github",
      "typeVersion": 1.1,
      "position": [
        144,
        1040
      ],
      "id": "573fd1ed-266b-4847-a96a-ae160c23d660",
      "name": "Fetch Humanization Prompt",
      "webhookId": "171c50fb-5a13-4b87-bdf6-6b800326e8f5",
      "credentials": {
        "githubApi": {
          "id": "pGlylAmPTa6t4Io0",
          "name": "GitHub account"
        }
      }
    },
    {
      "parameters": {
        "resource": "file",
        "operation": "get",
        "owner": {
          "__rl": true,
          "value": "cybernexcorps",
          "mode": "list",
          "cachedResultName": "cybernexcorps",
          "cachedResultUrl": "https://github.com/cybernexcorps"
        },
        "repository": {
          "__rl": true,
          "value": "case-study-generator",
          "mode": "list",
          "cachedResultName": "case-study-generator",
          "cachedResultUrl": "https://github.com/cybernexcorps/case-study-generator"
        },
        "filePath": "prompts/perplexity-research.md",
        "asBinaryProperty": false,
        "additionalParameters": {}
      },
      "type": "n8n-nodes-base.github",
      "typeVersion": 1.1,
      "position": [
        -240,
        1040
      ],
      "id": "41acd9e4-b347-405c-811b-4664ec50fe0b",
      "name": "Fetch Perplexity Prompt",
      "webhookId": "171c50fb-5a13-4b87-bdf6-6b800326e8f5",
      "credentials": {
        "githubApi": {
          "id": "pGlylAmPTa6t4Io0",
          "name": "GitHub account"
        }
      }
    },
    {
      "parameters": {
        "messages": {
          "message": [
            {
              "content": "={{ $('Assemble Prompts').item.json.prompts.perplexityResearch }}",
              "role": "system"
            },
            {
              "content": "=Case study request (in Russian):\n\n{{ $json.originalMessage }}\n\nPlease translate to English and provide structured research following the format above."
            }
          ]
        },
        "options": {
          "maxTokens": 1000,
          "temperature": 0.3
        },
        "requestOptions": {}
      },
      "type": "n8n-nodes-base.perplexity",
      "typeVersion": 1,
      "position": [
        784,
        848
      ],
      "id": "1cf55822-8e5d-4379-8260-e0553482671e",
      "name": "Research",
      "credentials": {
        "perplexityApi": {
          "id": "um7RpJwg4207ROLP",
          "name": "Perplexity account"
        }
      }
    },
    {
      "parameters": {
        "chatId": "={{ $node[\"Telegram Trigger\"].json.message.chat.id }}",
        "text": "=üöÄ –†–∞–±–æ—Ç–∞—é –Ω–∞–¥ –∫–µ–π—Å–æ–º: <b>{{ $node[\"Parse Telegram Input\"].json.topic }}</b>\n\n‚è≥ –û–∂–∏–¥–∞–π—Ç–µ, —ç—Ç–æ –∑–∞–π–º–µ—Ç –æ–∫–æ–ª–æ 1-2 –º–∏–Ω—É—Ç.",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        -448,
        1040
      ],
      "id": "e5dbe788-9222-464f-9371-0472e01b2561",
      "name": "Send Confirmation",
      "webhookId": "5e1992f7-3830-4f24-8ab5-a631c9d77ee7",
      "credentials": {
        "telegramApi": {
          "id": "BnEQsFHcvbF7jdMc",
          "name": "DDVB PR Case Study Bot"
        }
      }
    }
  ],
  "connections": {
    "Telegram Trigger": {
      "main": [
        [
          {
            "node": "Parse Telegram Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Assemble Prompts": {
      "main": [
        [
          {
            "node": "Route Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route Decision": {
      "main": [
        [
          {
            "node": "Research",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare OpenAI Request",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare OpenAI Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Research Data": {
      "main": [
        [
          {
            "node": "Prepare OpenAI Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare OpenAI Request": {
      "main": [
        [
          {
            "node": "Generate Russian Case Study1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Russian Case Study": {
      "main": [
        [
          {
            "node": "Humanize Russian Text1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Humanized Text": {
      "main": [
        [
          {
            "node": "Validate Russian Case Study",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Russian Case Study": {
      "main": [
        [
          {
            "node": "Split Message for Telegram",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Message for Telegram": {
      "main": [
        [
          {
            "node": "Send to Telegram",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Russian Case Study1": {
      "main": [
        [
          {
            "node": "Extract Russian Case Study",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Humanize Russian Text1": {
      "main": [
        [
          {
            "node": "Extract Humanized Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Generation Prompt": {
      "main": [
        [
          {
            "node": "Fetch Humanization Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Humanization Prompt": {
      "main": [
        [
          {
            "node": "Assemble Prompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Perplexity Prompt": {
      "main": [
        [
          {
            "node": "Fetch Generation Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Research": {
      "main": [
        [
          {
            "node": "Merge Research Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Telegram Input": {
      "main": [
        [
          {
            "node": "Send Confirmation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send Confirmation": {
      "main": [
        [
          {
            "node": "Fetch Perplexity Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": false
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {},
  "triggerCount": 1,
  "tags": [
    {
      "updatedAt": "2025-11-25T17:04:20.395Z",
      "createdAt": "2025-11-25T17:04:20.395Z",
      "id": "cZi2zQC8sBB8oNCI",
      "name": "PR"
    },
    {
      "updatedAt": "2025-11-17T15:56:02.170Z",
      "createdAt": "2025-11-17T15:56:02.170Z",
      "id": "yOZnROIlriaWeCLe",
      "name": "Content Creation"
    }
  ]
}